---
title: Genarate n-grams
weight: 60
draft: false
---

```{r message=FALSE}
require(quanteda)
```

```{r}
toks <- tokens(data_char_ukimmig2010)
```

You can generate n-grams in any lengths from a tokens using `tokens_ngrams()`. N-grams are a sequence of tokens from already tokenized text objects.

```{r}
toks_ngram <- tokens_ngrams(toks, n = 2:4)
head(toks_ngram[[1]], 50)
tail(toks_ngram[[1]], 50)
```

`tokens_ngrams()` also supports skip to generate skip-grams.

```{r}
skipgram <- tokens_ngrams(toks, n = 2, skip = 1:2)
head(skipgram[[1]], 50)
```

## Selective ngrams

While `tokens_ngrams()` generates n-grams or skip-grams in all possible combinations of tokens, `tokens_compound()` generates n-grams more selectively. For example, you can make negation bi-grams using `phrase()` and a wild card (`*`).

```{r}
neg_bigram <- tokens_compound(toks, pattern = phrase('not *'))
neg_bigram <- tokens_select(neg_bigram, pattern = phrase('not_*'))
head(neg_bigram[[1]], 50)
```

{{% notice tip %}}
`tokens_ngrans()` is an efficient function, but it returns a large object if multiple values are given to `n` or `skip`. Since n-grams inflates the size of objects without adding much information, we recommend to generate n-grams more selectively using `tokens_compound()`.
{{% /notice %}}
